{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'tkurth'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from os import makedirs, mkdir\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "%matplotlib inline\n",
    "import time\n",
    "import h5py\n",
    "#from helper_fxns import suppress_stdout_stderr\n",
    "import copy\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataIterator(object):\n",
    "    def __init__(self, filelist, batch_size=128, shuffle=True, keys=[\"data\",\"label\",\"weight\",\"normweight\"]):\n",
    "        #keys\n",
    "        self.keys=keys\n",
    "        #batchsize and indices\n",
    "        self.batch_size=batch_size\n",
    "        #store the filelist\n",
    "        self.files=filelist\n",
    "        self.num_files=len(self.files)\n",
    "        #store the shuffle state\n",
    "        self.shuffle=shuffle\n",
    "        #file and event indices:\n",
    "        self.file_index=0\n",
    "        self.event_index=0\n",
    "        #hgroup:\n",
    "        self.hgroup={}\n",
    "        \n",
    "        #determine how many events we have:\n",
    "        self.num_events=0\n",
    "        for fname in self.files:\n",
    "            f=h5py.File(fname,'r')\n",
    "            count=f[self.keys[0]].shape[0]\n",
    "            f.close()\n",
    "            self.num_events+=count\n",
    "        \n",
    "        #shuffle files\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.files)\n",
    "            \n",
    "        #load the initial bunch of data\n",
    "        self.load_next_file()\n",
    "    \n",
    "    \n",
    "    #iterator\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    #load next file logic\n",
    "    def load_next_file(self):\n",
    "        #open file\n",
    "        f=h5py.File(self.files[self.file_index],'r')\n",
    "        #load data from file\n",
    "        for key in self.keys:\n",
    "            self.hgroup[key]=f[key].value\n",
    "        #close file\n",
    "        f.close()\n",
    "        \n",
    "        #datalength:\n",
    "        self.dlength=self.hgroup[self.keys[0]].shape[0]\n",
    "        \n",
    "        #shuffle data if requested\n",
    "        if self.shuffle:\n",
    "            reindex=np.random.permutation(self.dlength)\n",
    "            for key in self.keys:\n",
    "                self.hgroup[key]=self.hgroup[key][reindex]\n",
    "    \n",
    "    #next function\n",
    "    def __next__(self):\n",
    "        #grep data\n",
    "        #upper index\n",
    "        upper=np.min([self.dlength,self.event_index+self.batch_size])\n",
    "        #load data\n",
    "        tmphgroup={}\n",
    "        for key in self.keys:\n",
    "            tmphgroup[key]=self.hgroup[key][self.event_index:upper]\n",
    "        \n",
    "        #tmpdata=self.data[self.event_index:upper,:,:,:].astype(\"float32\")\n",
    "        #tmplabel=self.label[self.event_index:upper].astype(\"int32\")\n",
    "        #tmpweight=self.weight[self.event_index:upper].astype(\"float32\")\n",
    "        #tmpnweight=self.nweight[self.event_index:upper].astype(\"float32\")\n",
    "        #load new file if needed:\n",
    "        if self.dlength<=(self.event_index+self.batch_size):\n",
    "            self.file_index+=1\n",
    "            \n",
    "            #check if the epoch is over\n",
    "            if self.file_index>=self.num_files:\n",
    "                #shuffle if requested\n",
    "                if self.shuffle:\n",
    "                    np.random.shuffle(self.files)\n",
    "                #reset indices\n",
    "                self.event_index=0\n",
    "                self.file_index=0\n",
    "                #prefetch next\n",
    "                self.load_next_file()\n",
    "                #stop the iteration here\n",
    "                raise StopIteration\n",
    "            else:\n",
    "                #prefetch the file\n",
    "                self.load_next_file()\n",
    "                #fetch the missing data:\n",
    "                rlength=self.batch_size-tmpdata.shape[0]\n",
    "                for key in self.keys:\n",
    "                    tmphgroup[key]=np.concatenate([tmphgroup[key],self.hgroup[key][0:rlength]],axis=0)\n",
    "                self.event_index=rlength\n",
    "        else:\n",
    "            self.event_index+=self.batch_size\n",
    "            \n",
    "        #return result\n",
    "        return tmphgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #set the filelists\n",
    "    mainpath='/global/cscratch1/sd/tkurth/atlas_dl/data_delphes'\n",
    "    trainfiles=[mainpath+'/'+x for x in os.listdir(mainpath) if x.startswith('hep_training_')]\n",
    "    validationfiles=[mainpath+'/'+x for x in os.listdir(mainpath) if x.startswith('hep_validation_')]\n",
    "    testfiles=[mainpath+'/'+x for x in os.listdir(mainpath) if x.startswith('hep_test_')]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
